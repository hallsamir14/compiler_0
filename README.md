# Pascal Compiler 

## **Lexical Analyzer**

Lexical analysis is the first layer of compilation and involves breaking down the input source code into a sequence of tokens for further processing by a compiler or interpreter. The primary goal of lexical   analysis is to simplify the code by converting it from a stream of characters into a stream of meaningful tokens.
A lexeme is the smallest unit of a programming language that has some meaning. It is the actual sequence of characters in the source code that represents a particular element in the language, such as a variable name, keyword, number, or symbol.
A token is a categorized or classified lexeme. It is a data structure that consists of two components: the token's type (also known as the token's name or category) and an optional attribute value (the actual value of the lexeme).

### Key components include:
- Source code (text or text file)
- Tokenization
- Handling whitespace and comments
- Error handling
- Symbol tables

## **Parser (Syntax Analysis)**

The parser takes the token stream generated by the lexer to check if it adheres to a given set of syntax rules of the programming language.
From an abstract perspective, a hierarchial strucutre is constructed that represents the program's syntax and semantics which will also lead to error handling of improper syntax.The output of the parser is an abstract syntax tree or equivalent representation.

## **Intpreter**

The interpreter utilizes the AST built by the parser to execute program statments/instructuions. Each node is interpreted in the tree, performing corresponding actions/computations.